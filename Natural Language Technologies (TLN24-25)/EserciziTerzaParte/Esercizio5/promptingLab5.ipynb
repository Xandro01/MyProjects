{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Cy19Y6tnen"
      },
      "source": [
        "# **Esercizio 5: task labeling con LLM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1bhY1uwtu8m",
        "outputId": "66e63768-1b07-43a0-a1a0-718c2b80b7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.40.2 in /usr/local/lib/python3.12/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.2) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.2) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.2) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.2) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.2) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.40.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.2) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.40.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.40.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.40.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.40.2) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.40.2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mc8shDS9r9qa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IuUsB3gVpVQ8"
      },
      "outputs": [],
      "source": [
        "def setup_model():\n",
        "    print(\"Verificando disponibilità GPU...\")\n",
        "    gpu_available = torch.cuda.is_available()\n",
        "    print(f\"GPU disponibile: {gpu_available}\")\n",
        "\n",
        "    print(\"Caricamento del modello...\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"microsoft/Phi-3.5-mini-instruct\",\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    print(\"Caricamento del tokenizer...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        \"microsoft/Phi-3.5-mini-instruct\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    print(\"Creazione della pipeline...\")\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        do_sample=True,\n",
        "        max_new_tokens=500,\n",
        "        temperature=0.2,\n",
        "        top_p=1\n",
        "    )\n",
        "\n",
        "    return pipe\n",
        "\n",
        "\n",
        "def generate_response(pipe, prompt):\n",
        "    \"\"\"\n",
        "    Genera una risposta usando il modello\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    output = pipe(messages)\n",
        "\n",
        "    generated_text = output[0][\"generated_text\"]\n",
        "\n",
        "\n",
        "    if isinstance(generated_text, list):\n",
        "\n",
        "        for message in generated_text:\n",
        "            if isinstance(message, dict) and message.get(\"role\") == \"assistant\":\n",
        "                return message.get(\"content\", \"\")\n",
        "        return \"\"\n",
        "    else:\n",
        "        # If it's a string, remove the prompt if it's included\n",
        "        if generated_text.startswith(prompt):\n",
        "            generated_text = generated_text[len(prompt):].lstrip()\n",
        "        return generated_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratorio N. 5"
      ],
      "metadata": {
        "id": "IEJakOcI5GIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Come attività pratica, si propone un esercizio di labeling su due sottotask (5.1 e 5.2):\n",
        " 1.  Generare etichette per i topic del laboratorio n.4. 2.\n",
        " 2. Indovinare le parole sulla base delle definizioni dei\n",
        "laboratori n.2 e n.3.\n",
        "Si raccomanda di utilizzare prompt ben progettati e ragionati, in maniera iterativa, selezionando bene i dati da includere nei prompt e in generale seguendo le strategie apprese in questo capitolo."
      ],
      "metadata": {
        "id": "CMTNPsSZ5MZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lab 5.1**"
      ],
      "metadata": {
        "id": "v_73OsWT5e60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funzioni di utilità"
      ],
      "metadata": {
        "id": "Q7ORKDnC6F6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topic_prompt(index, topic, weight):\n",
        "  prompt = \"\"\n",
        "  for word in topic:\n",
        "    prompt = prompt + \", \" + word + \"(\" + str(weight[topic.index(word)]) + \")\"\n",
        "  return \"\"\"Topic: \"\"\" + str(index) +\"\"\": <INPUT>: \"\"\" + prompt\n",
        "\n",
        "def get_labels_prompt(topics, weights):\n",
        "  topics_prompt = \"\"\n",
        "  for topic in topics:\n",
        "    topics_prompt = topics_prompt + \" \" + get_topic_prompt(topics.index(topic), topic, weights[topics.index(topic)])\n",
        "\n",
        "\n",
        "  labeling_prompt = \"\"\"Make a liast of labels for some topics, the topic is a list of words more used in the document with the weight, greater is the weight mor is used the word in the document. The OUTPUT is the label of the given untitled topic. The INPUT is the topic.\n",
        "       Example of input - output: Topic: 0 <INPUT>: generative(0.023), model(0.013), probabilistic(0.033), robot(0.019), task(0.022) Topic: 1 <INPUT>: student(0.023), book(0.013), lesson(0.033), teacher(0.019), result(0.022) <OUTPUT>: \"School\"\n",
        "       ## the real input is:\n",
        "       \"\"\" + topics_prompt\n",
        "  return labeling_prompt\n",
        "\n",
        "def get_label_prompt(topic, weight):\n",
        "  labeling_prompt = \"\"\"Make a label for a topic, the topic is a list of words more used in the document with the weight, greater is the weight mor is used the word in the document. The OUTPUT is the label of the given untitled topic. The INPUT is the topic.\n",
        "     Example of input - output: <INPUT>: generative(0.023), model(0.013), probabilistic(0.033), robot(0.019), task(0.022) <OUTPUT>: \"Artificial inteligence\"\n",
        "     ## the real input is:\n",
        "       \"\"\" + get_topic_prompt(0, topic, weight)\n",
        "  return labeling_prompt\n",
        "\n",
        "def get_response( prompt: str, pipe ):\n",
        "  labeling_response = generate_response(pipe, prompt)\n",
        "  return labeling_response"
      ],
      "metadata": {
        "id": "2GysLYOH50hc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Codice"
      ],
      "metadata": {
        "id": "m37VLRB_6M_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = setup_model()"
      ],
      "metadata": {
        "id": "IUWbXzOR56c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "e7e24da692be448084a6019c6616672b",
            "6e52592d21024ccca2f4cd973c557b77",
            "962fe89caf084efbaa352dfbb89398dc",
            "a58adad354744db18f62b66d58de630c",
            "b2154ff722334277a5bf08492317acaf",
            "62da829ea85b492a8c7cbcdb31d8898d",
            "0d63d7d5337b4673be3ada6640f07806",
            "1004b259a5eb4b8984fe9b4095aa728b",
            "cd2a1c5483ad491c8c988fc62faeb6cd",
            "983bc0cc2498455f9ba09d5c32e71d90",
            "618cd7be08284bff9f24a34a703a77e4"
          ]
        },
        "outputId": "9a735b86-1859-4ffe-eda3-48869c673e94"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verificando disponibilità GPU...\n",
            "GPU disponibile: True\n",
            "Caricamento del modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.3145e03a9fd4cdd7cd953c34d9bbf7ad606122ca.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.3145e03a9fd4cdd7cd953c34d9bbf7ad606122ca.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7e24da692be448084a6019c6616672b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caricamento del tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creazione della pipeline...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics = [\n",
        "  [\"trump\", \"white\", \"black\", \"peaple\", \"donald\"],\n",
        "  [\"russia\", \"russian\", \"trump\", \"fbi\", \"say\"],\n",
        "  [\"korea\", \"china\", \"north\", \"say\", \"nuclear\"],\n",
        "  [\"clinton\", \"sanders\", \"hillary\", \"campaign\", \"bernie\"],\n",
        "  [\"immigration\", \"ban\", \"immigrant\", \"order\", \"court\"],\n",
        "  [\"cruz\", \"trump\", \"rubio\", \"republican\", \"ted\"],\n",
        "  [\"merkel\", \"european\", \"germany\", \"macron\", \"party\"],\n",
        "  [\"muslim\", \"attack\", \"say\", \"police\", \"london\"]\n",
        "]\n",
        "weights = [\n",
        "  [0.041, 0.022, 0.021, 0.020, 0.018],\n",
        "  [0.038, 0.033, 0.029, 0.026, 0.025],\n",
        "  [0.049, 0.049, 0.046, 0.032, 0.028],\n",
        "  [0.071, 0.048, 0.041, 0.030, 0.022],\n",
        "  [0.040, 0.031, 0.030, 0.030, 0.028],\n",
        "  [0.082, 0.039, 0.039, 0.034, 0.030],\n",
        "  [0.052, 0.038, 0.038, 0.038, 0.030],\n",
        "  [0.031, 0.022, 0.020, 0.019, 0.019]\n",
        "]\n",
        "\n",
        "\n",
        "get_response(get_label_prompt( topics[0] , weights[0]), pipe)\n",
        "results = []\n",
        "\n",
        "for topic in topics:\n",
        "  response = get_response(get_label_prompt(topic, weights[topics.index(topic)]), pipe)\n",
        "  results.append(response)\n",
        "\n",
        "index = 1\n",
        "for result in results:\n",
        "  print(\"----- Topic \" + str(index) + \" -------- \" )\n",
        "  print(result)\n",
        "  print(\"----------------------------------------\")\n",
        "  index += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"---- With all topic -------\")\n",
        "all_results = get_response(get_labels_prompt(topics, weights), pipe)\n",
        "print(all_results)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3pOWW-s659eU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2db8060-9cb7-46d8-c07a-47bc6409f701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Topic 1 -------- \n",
            " <OUTPUT>: \"Political discourse and racial themes\"\n",
            "\n",
            "Explanation: The given words are related to political figures (Donald Trump) and racial demographics (white, black, people). The frequency of these words suggests that the topic revolves around discussions or themes involving politics, particularly in the context of racial issues or demographics. Hence, the label \"Political discourse and racial themes\" encapsulates the essence of the topic.\n",
            "----------------------------------------\n",
            "----- Topic 2 -------- \n",
            " <OUTPUT>: \"US-Russia Relations and Investigations\"\n",
            "\n",
            "Explanation: The given words are related to geopolitical events, particularly involving Russia, the United States, and investigative bodies like the FBI. The terms \"Russia,\" \"Russian,\" and \"Trump\" suggest a focus on US-Russia relations, possibly in the context of political or investigative matters. The presence of \"FBI\" indicates an investigative angle, and \"say\" could imply statements or comments from involved parties. Combining these elements, the label \"US-Russia Relations and Investigations\" encapsulates the topic's essence, reflecting the weight and context of the words provided.\n",
            "----------------------------------------\n",
            "----- Topic 3 -------- \n",
            " <OUTPUT>: \"North Korea Nuclear Issues\"\n",
            "\n",
            "Explanation: The given words suggest a topic related to geopolitical tensions, specifically focusing on North Korea's nuclear capabilities. \"North Korea\" and \"nuclear\" are central to the topic, while \"China\" might be involved as a regional player or influencer. The other terms like \"say\" could relate to statements or positions taken by involved parties. Thus, the label \"North Korea Nuclear Issues\" encapsulates the main theme of the topic based on the weighted words provided.\n",
            "----------------------------------------\n",
            "----- Topic 4 -------- \n",
            " <OUTPUT>: \"US Presidential Election Campaigns\"\n",
            "\n",
            "Explanation: The given words are related to political figures (Clinton, Sanders, Hillary, Bernie) and the context of a campaign. This suggests that the topic is about the US Presidential Election Campaigns, where these individuals are significant players or subjects of discussion. The weights indicate the frequency or prominence of these terms in the document, reinforcing the political theme.\n",
            "----------------------------------------\n",
            "----- Topic 5 -------- \n",
            " <OUTPUT>: \"Immigration Policy and Legal Issues\"\n",
            "\n",
            "Explanation: The given words are related to immigration, legal proceedings, and regulatory actions. The terms \"immigration,\" \"ban,\" \"immigrant,\" \"order,\" and \"court\" suggest a topic centered around immigration policy, legal challenges, and enforcement. Therefore, the label \"Immigration Policy and Legal Issues\" encapsulates the essence of the topic based on the weighted frequency of the mentioned words.\n",
            "----------------------------------------\n",
            "----- Topic 6 -------- \n",
            " <OUTPUT>: \"Political Discourse in the United States\"\n",
            "\n",
            "Explanation: The given words are associated with prominent political figures (Cruz, Trump, Rubio) and political parties (Republican), along with a reference to Ted, possibly a political figure or context. The weights indicate their frequency or importance in the document. This suggests the topic revolves around political discussions, debates, or events in the United States.\n",
            "----------------------------------------\n",
            "----- Topic 7 -------- \n",
            " <OUTPUT>: \"German Politics and European Union\"\n",
            "\n",
            "Explanation: The given words indicate a topic related to German politics and its influence within the European Union. 'Merkel' refers to Angela Merkel, a prominent German politician who served as the Chancellor of Germany. The term 'European' and 'Germany' suggest a focus on European affairs, while 'Macron' refers to Emmanuel Macron, the President of France, indicating a broader European context. 'Party' suggests political entities or groups involved. Thus, the label \"German Politics and European Union\" encapsulates the essence of the topic.\n",
            "----------------------------------------\n",
            "----- Topic 8 -------- \n",
            " <OUTPUT>: \"London Islamic Attacks and Discourse\"\n",
            "\n",
            "Explanation: The given words suggest a topic related to events or discussions involving Muslims, attacks, and the police in London. The label \"London Islamic Attacks and Discourse\" encapsulates these elements, indicating a focus on incidents and conversations about Islamic-related attacks in the city of London. The weight of each word reflects its relative importance or frequency in the context of the topic.\n",
            "----------------------------------------\n",
            "\n",
            "---- With all topic -------\n",
            " Topic: 0 - \"Politics/Current Events\"\n",
            "Topic: 1 - \"International Relations\"\n",
            "Topic: 2 - \"Nuclear Issues/Security\"\n",
            "Topic: 3 - \"Political Campaigns/Elections\"\n",
            "Topic: 4 - \"Immigration Policy\"\n",
            "Topic: 5 - \"US Politics/Partisan Debates\"\n",
            "Topic: 6 - \"European Politics\"\n",
            "Topic: 7 - \"Societal Issues/Religious Tensions\"\n",
            "\n",
            "Each label represents the overarching theme or subject matter that the words and their associated weights suggest in the given topics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----- Topic 1 --------\n",
        "\n",
        "Political discourse and racial themes\n",
        "\n",
        "- Explanation: The given words are related to political figures (Donald Trump) and racial demographics (white, black, people). The frequency of these words suggests that the topic revolves around discussions or themes involving politics, particularly in the context of racial issues or demographics. Hence, the label \"Political discourse and racial themes\" encapsulates the essence of the topic.\n",
        "----------------------------------------\n",
        "----- Topic 2 --------\n",
        " <OUTPUT>: \"US-Russia Relations and Investigations\"\n",
        "\n",
        "- Explanation: The given words are related to geopolitical events, particularly involving Russia, the United States, and investigative bodies like the FBI. The terms \"Russia,\" \"Russian,\" and \"Trump\" suggest a focus on US-Russia relations, possibly in the context of political or investigative matters. The presence of \"FBI\" indicates an investigative angle, and \"say\" could imply statements or comments from involved parties. Combining these elements, the label \"US-Russia Relations and Investigations\" encapsulates the topic's essence, reflecting the weight and context of the words provided.\n",
        "----------------------------------------\n",
        "----- Topic 3 --------\n",
        " <OUTPUT>: \"North Korea Nuclear Issues\"\n",
        "\n",
        "- Explanation: The given words suggest a topic related to geopolitical tensions, specifically focusing on North Korea's nuclear capabilities. \"North Korea\" and \"nuclear\" are central to the topic, while \"China\" might be involved as a regional player or influencer. The other terms like \"say\" could relate to statements or positions taken by involved parties. Thus, the label \"North Korea Nuclear Issues\" encapsulates the main theme of the topic based on the weighted words provided.\n",
        "----------------------------------------\n",
        "----- Topic 4 --------\n",
        " <OUTPUT>: \"US Presidential Election Campaigns\"\n",
        "\n",
        "- Explanation: The given words are related to political figures (Clinton, Sanders, Hillary, Bernie) and the context of a campaign. This suggests that the topic is about the US Presidential Election Campaigns, where these individuals are significant players or subjects of discussion. The weights indicate the frequency or prominence of these terms in the document, reinforcing the political theme.\n",
        "----------------------------------------\n",
        "----- Topic 5 --------\n",
        " <OUTPUT>: \"Immigration Policy and Legal Issues\"\n",
        "\n",
        "- Explanation: The given words are related to immigration, legal proceedings, and regulatory actions. The terms \"immigration,\" \"ban,\" \"immigrant,\" \"order,\" and \"court\" suggest a topic centered around immigration policy, legal challenges, and enforcement. Therefore, the label \"Immigration Policy and Legal Issues\" encapsulates the essence of the topic based on the weighted frequency of the mentioned words.\n",
        "----------------------------------------\n",
        "----- Topic 6 --------\n",
        " <OUTPUT>: \"Political Discourse in the United States\"\n",
        "\n",
        "- Explanation: The given words are associated with prominent political figures (Cruz, Trump, Rubio) and political parties (Republican), along with a reference to Ted, possibly a political figure or context. The weights indicate their frequency or importance in the document. This suggests the topic revolves around political discussions, debates, or events in the United States.\n",
        "----------------------------------------\n",
        "----- Topic 7 --------\n",
        " <OUTPUT>: \"German Politics and European Union\"\n",
        "\n",
        "- Explanation: The given words indicate a topic related to German politics and its influence within the European Union. 'Merkel' refers to Angela Merkel, a prominent German politician who served as the Chancellor of Germany. The term 'European' and 'Germany' suggest a focus on European affairs, while 'Macron' refers to Emmanuel Macron, the President of France, indicating a broader European context. 'Party' suggests political entities or groups involved. Thus, the label \"German Politics and European Union\" encapsulates the essence of the topic.\n",
        "----------------------------------------\n",
        "----- Topic 8 --------\n",
        " <OUTPUT>: \"London Islamic Attacks and Discourse\"\n",
        "\n",
        "- Explanation: The given words suggest a topic related to events or discussions involving Muslims, attacks, and the police in London. The label \"London Islamic Attacks and Discourse\" encapsulates these elements, indicating a focus on incidents and conversations about Islamic-related attacks in the city of London. The weight of each word reflects its relative importance or frequency in the context of the topic.\n",
        "----------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "---- With all topic -------\n",
        "\n",
        "Topic: 0 - \"Politics/Current Events\"\n",
        "\n",
        "Topic: 1 - \"International Relations\"\n",
        "\n",
        "Topic: 2 - \"Nuclear Issues/Security\"\n",
        "\n",
        "Topic: 3 - \"Political Campaigns/Elections\"\n",
        "\n",
        "Topic: 4 - \"Immigration Policy\"\n",
        "\n",
        "Topic: 5 - \"US Politics/Partisan Debates\"\n",
        "\n",
        "Topic: 6 - \"European Politics\"\n",
        "\n",
        "Topic: 7 - \"Societal Issues/Religious Tensions\"\n",
        "\n",
        "\n",
        "Each label represents the overarching theme or subject matter that the words and their associated weights suggest in the given topics."
      ],
      "metadata": {
        "id": "BqqLisilXuw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lab 5.2**"
      ],
      "metadata": {
        "id": "V-3kTgNn5heB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_top_k_terms(json_path=None):\n",
        "\n",
        "    if json_path is None:\n",
        "        # Percorso di default relativo alla struttura del progetto\n",
        "        json_path = \"/content/sample_data/top_4_terms_in_definitions.json\"\n",
        "\n",
        "    try:\n",
        "        with open(json_path, 'r', encoding='utf-8') as f:\n",
        "            top_k_data = json.load(f)\n",
        "        print(f\"Caricati dati per {len(top_k_data)} concetti dal file JSON\")\n",
        "        return top_k_data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File JSON non trovato: {json_path}\")\n",
        "        return {}\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Errore nel parsing del file JSON: {json_path}\")\n",
        "        return {}"
      ],
      "metadata": {
        "id": "Jh-sftrt_WdC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def content_to_form_labeling(pipe, prompt_data, word):\n",
        "    list_of_top_k_terms = prompt_data[word][\"terms\"]\n",
        "    definition = prompt_data[word][\"definition\"]\n",
        "    terms = [(item[\"term\"], item[\"count\"]) for item in list_of_top_k_terms]\n",
        "    labeling_prompt = f\"\"\"\n",
        "    Un insieme di definizioni sono associate ad un termine. Da queste definizioni vengono estratte le parole più frequenti.\n",
        "    Esegui un compito di labeling trovando il termine associato alle definizioni avendo a disposizione la lista delle parole più frequenti nelle definizioni.\n",
        "    INPUT: [{terms}] lista di tuple (parola, conteggio) delle  parole più frequenti presenti nell'insieme di definizioni del termine da trovare. Viene inoltre fornita una definizione di esempio: '{definition}'\n",
        "    OUTPUT: il termine è rappresentato da una singola parola (sostantivo comune al singolare).\n",
        "    Ad esempio se le parole più frequenti sono [(gioco, 40), (bambini, 33), (giardino, 22), (divertimento, 10)] il termine è altalena.\n",
        "    Per svolgere il compito procedi per passi:\n",
        "    1) osserva la lista di (parole, frequenze) data in input e deall'esempio di definizione fornita in input.\n",
        "    2) estrai informazioni da esse, trovando delle relazioni tra queste parole, aiutandoti a capire a quale termine quella definizione è associata.\n",
        "    3) utilizzare tutte le informazioni per risalire al termine.\n",
        "    \"\"\"\n",
        "    response = generate_response(pipe, labeling_prompt)\n",
        "    return response\n",
        "\n",
        "\n",
        "\n",
        "def content_to_form_labeling_abstract_term(pipe, prompt_data, word):\n",
        "    list_of_top_k_terms = prompt_data[word][\"terms\"]\n",
        "    definition = prompt_data[word][\"definition\"]\n",
        "    terms = [(item[\"term\"], item[\"count\"]) for item in list_of_top_k_terms]\n",
        "    labeling_prompt = f\"\"\"\n",
        "    Un insieme di definizioni sono associate ad un termine. Da queste definizioni vengono estratte le parole più frequenti.\n",
        "    Esegui un compito di labeling trovando il termine associato alle definizioni avendo a disposizione la lista delle parole più frequenti nelle definizioni.\n",
        "    INPUT: [{terms}] lista di tuple (parola, conteggio) delle parole più frequenti presenti nell'insieme di definizioni del termine da trovare. Viene inoltre fornita una definizione di esempio: '{definition}'\n",
        "    OUTPUT: il termine rappresentato da una singola parola (sostantivo comune al singolare).\n",
        "\n",
        "    Per svolgere il compito procedi per passi:\n",
        "    1) Lavora in italiano.\n",
        "    2) osserva la lista di (parole, frequenze) data in input e deall'esempio di definizione fornita in input.\n",
        "    3) estrai informazioni da esse, trovando delle relazioni tra queste parole, aiutandoti a capire a quale termine quella definizione è associata.\n",
        "    4) utilizzare tutte le informazioni per risalire al termine astratto. Scegli la forma più comune e generale in italiano.\n",
        "    \"\"\"\n",
        "    response = generate_response(pipe, labeling_prompt)\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "-Tgsz-W7AB9f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8StI-1epVQ-",
        "outputId": "56525527-2916-4ad0-d533-f14a75ad0914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caricati dati per 4 concetti dal file JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.3145e03a9fd4cdd7cd953c34d9bbf7ad606122ca.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risultato del labeling:\n",
            " Basato sulle informazioni fornite e sulla definizione di esempio, il termine associato alle parole più frequenti [(gamba, 26), (indumento, 25), (parte, 17), (corpo, 15)] è 'gambale'.\n",
            "\n",
            "Ecco il ragionamento passo dopo passo:\n",
            "\n",
            "1) Osserva la lista di (parole, frequenze): gamba (26), indumento (25), parte (17), corpo (15).\n",
            "2) Analizza la definizione di esempio: 'indumento per coprire le gambe'. Qui, 'indumento' e 'gamba' sono le parole chiave che descrivono il concetto.\n",
            "3) Relaziona le parole più frequenti con la definizione di esempio. 'Gamba' e 'indumento' sono presenti sia nella definizione di esempio che nella lista delle parole più frequenti.\n",
            "4) Dato che 'gamba' è un sostantivo comune al singolare e è presente sia nella definizione di esempio che nella lista delle parole più frequenti, si può dedurre che il termine è 'gambale'.\n",
            "\n",
            "Quindi, l'OUTPUT è: il termine è 'gambale'.\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #pipe = setup_model()\n",
        "\n",
        "    top_k_terms = load_top_k_terms()\n",
        "\n",
        "    labeling_response = content_to_form_labeling(pipe, top_k_terms, 'Pantalone')\n",
        "    print(\"Risultato del labeling:\")\n",
        "    print(labeling_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caricati dati per 4 concetti dal file JSON\n",
        "\n",
        "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.3145e03a9fd4cdd7cd953c34d9bbf7ad606122ca.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n",
        "\n",
        "Risultato del labeling:\n",
        " Basato sulle informazioni fornite e sulla definizione di esempio, il termine associato alle parole più frequenti [(gamba, 26), (indumento, 25), (parte, 17), (corpo, 15)] è 'gambale'.\n",
        "\n",
        "Ecco il ragionamento passo dopo passo:\n",
        "\n",
        "1) Osserva la lista di (parole, frequenze): gamba (26), indumento (25), parte (17), corpo (15).\n",
        "2) Analizza la definizione di esempio: 'indumento per coprire le gambe'. Qui, 'indumento' e 'gamba' sono le parole chiave che descrivono il concetto.\n",
        "3) Relaziona le parole più frequenti con la definizione di esempio. 'Gamba' e 'indumento' sono presenti sia nella definizione di esempio che nella lista delle parole più frequenti.\n",
        "4) Dato che 'gamba' è un sostantivo comune al singolare e è presente sia nella definizione di esempio che nella lista delle parole più frequenti, si può dedurre che il termine è 'gambale'.\n",
        "\n",
        "Quindi, l'OUTPUT è: il termine è 'gambale'.\n"
      ],
      "metadata": {
        "id": "1-osnOg133uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #pipe = setup_model()\n",
        "\n",
        "    top_k_terms = load_top_k_terms()\n",
        "\n",
        "    labeling_response = content_to_form_labeling(pipe, top_k_terms, 'Microscopio')\n",
        "    print(\"Risultato del labeling:\")\n",
        "    print(labeling_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQJgGRgH3-M5",
        "outputId": "ecf29365-2837-4c28-b796-a2918d239128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caricati dati per 4 concetti dal file JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.3145e03a9fd4cdd7cd953c34d9bbf7ad606122ca.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risultato del labeling:\n",
            " Basato sulle informazioni fornite e sull'esempio, il termine associato alle parole più frequenti [(strumento, 32), (oggetto, 21), (piccolo, 15), (scientifico, 14)] e alla definizione 'Strumento che permette di ingrandire oggetti ed elementi fino a una scala impossibile da raggiungere ad occhio nudo' è probabilmente 'Microscopio'.\n",
            "\n",
            "Ecco il ragionamento passo dopo passo:\n",
            "\n",
            "1) Osserva la lista di parole più frequenti e la definizione:'strumento', 'oggetto', 'piccolo','scientifico'. Queste parole si riferiscono a un dispositivo utilizzato per ingrandire oggetti, che è un aspetto scientifico.\n",
            "\n",
            "2) Relaziona le parole con la definizione:'strumento' e'scientifico' suggeriscono che il termine è un dispositivo utilizzato per scopi scientifici. 'oggetto' e 'piccolo' suggeriscono che questo dispositivo viene utilizzato per ingrandire oggetti piccoli.\n",
            "\n",
            "3) Utilizza queste informazioni per risalire al termine: Considerando le parole e il loro contesto nella definizione, il termine che meglio si adatta è 'Microscopio'. Un microscopio è uno strumento scientifico utilizzato per ingrandire oggetti piccoli al di là della portata dell'occhio umano.\n",
            "\n",
            "Quindi, l'output è: Microscopio.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etichettatura per \"Microscopio\":\n",
        "\n",
        "Caricati dati per 4 concetti dal file JSON\n",
        "\n",
        "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.3145e03a9fd4cdd7cd953c34d9bbf7ad606122ca.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n",
        "\n",
        "Risultato del labeling:\n",
        " Basato sulle informazioni fornite e sull'esempio, il termine associato alle parole più frequenti [(strumento, 32), (oggetto, 21), (piccolo, 15), (scientifico, 14)] e alla definizione 'Strumento che permette di ingrandire oggetti ed elementi fino a una scala impossibile da raggiungere ad occhio nudo' è probabilmente 'Microscopio'.\n",
        "\n",
        "Ecco il ragionamento passo dopo passo:\n",
        "\n",
        "1) Osserva la lista di parole più frequenti e la definizione:'strumento', 'oggetto', 'piccolo','scientifico'. Queste parole si riferiscono a un dispositivo utilizzato per ingrandire oggetti, che è un aspetto scientifico.\n",
        "\n",
        "2) Relaziona le parole con la definizione:'strumento' e'scientifico' suggeriscono che il termine è un dispositivo utilizzato per scopi scientifici. 'oggetto' e 'piccolo' suggeriscono che questo dispositivo viene utilizzato per ingrandire oggetti piccoli.\n",
        "\n",
        "3) Utilizza queste informazioni per risalire al termine: Considerando le parole e il loro contesto nella definizione, il termine che meglio si adatta è 'Microscopio'. Un microscopio è uno strumento scientifico utilizzato per ingrandire oggetti piccoli al di là della portata dell'occhio umano.\n",
        "\n",
        "Quindi, l'output è: Microscopio.\n"
      ],
      "metadata": {
        "id": "0oUAa91G6ghO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #pipe = setup_model()\n",
        "\n",
        "    top_k_terms = load_top_k_terms()\n",
        "\n",
        "    labeling_response = content_to_form_labeling_abstract_term(pipe, top_k_terms, 'Euristica')\n",
        "    print(\"Risultato del labeling:\")\n",
        "    print(labeling_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEL4_roz6so7",
        "outputId": "76764983-d33f-4346-95b4-2e86ba398712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caricati dati per 4 concetti dal file JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.3145e03a9fd4cdd7cd953c34d9bbf7ad606122ca.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risultato del labeling:\n",
            " Basato sulle informazioni fornite e sulla relazione tra le parole più frequenti ('ricerca', 'problema','strategia', 'utilizzare') e la definizione di esempio ('regola che permette di approssimare una soluzione ottima a un problema'), il termine astratto associato a queste definizioni è probabilmente'metodo'.\n",
            "\n",
            "Spiegazione:\n",
            "- 'ricerca' e 'problema' implicano l'indagine o la soluzione di qualcosa.\n",
            "-'strategia' suggerisce un piano o un approccio per raggiungere un obiettivo.\n",
            "- 'utilizzare' indica l'applicazione di qualcosa.\n",
            "\n",
            "Unendo queste idee,'metodo' emerge come termine astratto che comprende l'idea di un approccio strutturato (strategia), utilizzato per risolvere un problema (ricerca e problema) e applicato in un contesto specifico (utilizzare).\n",
            "\n",
            "Quindi, il termine associato alle definizioni e alla definizione di esempio è'metodo'. In italiano, la forma più comune e generale di questo termine è'metodo' (sostantivo comune al singolare).\n",
            "\n",
            "OUTPUT: metodo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etichettatura per Euristica:\n",
        "\n",
        "Caricati dati per 4 concetti dal file JSON\n",
        "\n",
        "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.3145e03a9fd4cdd7cd953c34d9bbf7ad606122ca.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n",
        "\n",
        "Risultato del labeling:\n",
        " Basato sulle informazioni fornite e sulla relazione tra le parole più frequenti ('ricerca', 'problema','strategia', 'utilizzare') e la definizione di esempio ('regola che permette di approssimare una soluzione ottima a un problema'), il termine astratto associato a queste definizioni è probabilmente'metodo'.\n",
        "\n",
        "Spiegazione:\n",
        "- 'ricerca' e 'problema' implicano l'indagine o la soluzione di qualcosa.\n",
        "-'strategia' suggerisce un piano o un approccio per raggiungere un obiettivo.\n",
        "- 'utilizzare' indica l'applicazione di qualcosa.\n",
        "\n",
        "Unendo queste idee,'metodo' emerge come termine astratto che comprende l'idea di un approccio strutturato (strategia), utilizzato per risolvere un problema (ricerca e problema) e applicato in un contesto specifico (utilizzare).\n",
        "\n",
        "Quindi, il termine associato alle definizioni e alla definizione di esempio è'metodo'. In italiano, la forma più comune e generale di questo termine è'metodo' (sostantivo comune al singolare).\n",
        "\n",
        "OUTPUT: metodo\n"
      ],
      "metadata": {
        "id": "biD6hSKA_CqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #pipe = setup_model()\n",
        "\n",
        "    top_k_terms = load_top_k_terms()\n",
        "\n",
        "    labeling_response = content_to_form_labeling_abstract_term(pipe, top_k_terms, 'Pericolo')\n",
        "    print(\"Risultato del labeling:\")\n",
        "    print(labeling_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUmdKnWH_Fmu",
        "outputId": "bca0b9ef-9515-4220-a464-343cf7c28a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caricati dati per 4 concetti dal file JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.3145e03a9fd4cdd7cd953c34d9bbf7ad606122ca.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risultato del labeling:\n",
            " Basato sulle informazioni fornite e sulla relazione tra le parole più frequenti ('situazione', 'persona', 'incolumità', 'il'), insieme alla definizione di esempio ('Percezione umana innescata da un evento che mina la sicurezza del soggetto'), il termine astratto che meglio si adatta è 'pericolo'.\n",
            "\n",
            "Questo perché:\n",
            "-'situazione' si riferisce a una condizione o stato particolare.\n",
            "- 'persona' può essere il soggetto di tale situazione.\n",
            "- 'incolumità' è legata alla sicurezza o alla protezione della persona.\n",
            "- 'il' è un articolo che introduce il concetto di pericolo.\n",
            "\n",
            "Quindi, il termine astratto che collega tutte queste parole e corrisponde alla definizione data è 'pericolo'. In italiano, la forma più comune e generale di questo termine è 'pericolo'.\n",
            "\n",
            "OUTPUT: pericolo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caricati dati per 4 concetti dal file JSON\n",
        "\n",
        "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.3145e03a9fd4cdd7cd953c34d9bbf7ad606122ca.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n",
        "\n",
        "Risultato del labeling:\n",
        " Basato sulle informazioni fornite e sulla relazione tra le parole più frequenti ('situazione', 'persona', 'incolumità', 'il'), insieme alla definizione di esempio ('Percezione umana innescata da un evento che mina la sicurezza del soggetto'), il termine astratto che meglio si adatta è 'pericolo'.\n",
        "\n",
        "Questo perché:\n",
        "-'situazione' si riferisce a una condizione o stato particolare.\n",
        "- 'persona' può essere il soggetto di tale situazione.\n",
        "- 'incolumità' è legata alla sicurezza o alla protezione della persona.\n",
        "- 'il' è un articolo che introduce il concetto di pericolo.\n",
        "\n",
        "Quindi, il termine astratto che collega tutte queste parole e corrisponde alla definizione data è 'pericolo'. In italiano, la forma più comune e generale di questo termine è 'pericolo'.\n",
        "\n",
        "OUTPUT: pericolo\n"
      ],
      "metadata": {
        "id": "STTsepI2Bepq"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7e24da692be448084a6019c6616672b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e52592d21024ccca2f4cd973c557b77",
              "IPY_MODEL_962fe89caf084efbaa352dfbb89398dc",
              "IPY_MODEL_a58adad354744db18f62b66d58de630c"
            ],
            "layout": "IPY_MODEL_b2154ff722334277a5bf08492317acaf"
          }
        },
        "6e52592d21024ccca2f4cd973c557b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62da829ea85b492a8c7cbcdb31d8898d",
            "placeholder": "​",
            "style": "IPY_MODEL_0d63d7d5337b4673be3ada6640f07806",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "962fe89caf084efbaa352dfbb89398dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1004b259a5eb4b8984fe9b4095aa728b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd2a1c5483ad491c8c988fc62faeb6cd",
            "value": 2
          }
        },
        "a58adad354744db18f62b66d58de630c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_983bc0cc2498455f9ba09d5c32e71d90",
            "placeholder": "​",
            "style": "IPY_MODEL_618cd7be08284bff9f24a34a703a77e4",
            "value": " 2/2 [00:39&lt;00:00, 18.87s/it]"
          }
        },
        "b2154ff722334277a5bf08492317acaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62da829ea85b492a8c7cbcdb31d8898d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d63d7d5337b4673be3ada6640f07806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1004b259a5eb4b8984fe9b4095aa728b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd2a1c5483ad491c8c988fc62faeb6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "983bc0cc2498455f9ba09d5c32e71d90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618cd7be08284bff9f24a34a703a77e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}